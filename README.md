# MoMo Analytics

GROUP 8

Process, analyze, and visualize Mobile Money (MoMo) SMS data endâ€‘toâ€‘end. This project ingests XML exports of SMS, cleans and categorizes transactions, loads them into a relational database (SQLite for now), and powers a lightweight analytics dashboard for insights.


âœ¨ Key Features

ETL Pipeline: Parse XML â†’ Clean & Normalize â†’ Categorize â†’ Load to DB
Relational Storage (SQLite): Durable, queryable transaction history
Analytics-Ready Outputs: Aggregations for charts, KPIs, and tables
Simple Frontend Dashboard: HTML/CSS/JS visualizations
Optional API (FastAPI): Serve transactions and analytics programmatically
Environment-Driven Config: Reproducible runs across machines



ğŸ§­ Architecture Diagram


   <img width="190" height="519" alt="image" src="https://github.com/user-attachments/assets/de797767-ae43-41ac-b71a-74cf47d3f76e" />



 ğŸ§± Scrum Board
 



 ğŸ§° Tech Stack

  Language: Python 3.x
  ETL: Standard library + lxml (or ElementTree), Pandas (optional), custom cleaners
  Database: SQLite (dev). Ready to swap to Postgres later
  API (optional): FastAPI + Uvicorn
  Frontend: HTML, CSS, vanilla JS (Chart.js or similar)
  Config: .env with environment variables
  Testing: pytest



ğŸ“ Project Structure (Planned)

```
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ index.html
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ chart_handler.js
â”‚   â””â”€â”€ assets/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ db.sqlite3
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ parse_xml.py
â”‚   â”œâ”€â”€ clean_normalize.py
â”‚   â”œâ”€â”€ categorize.py
â”‚   â”œâ”€â”€ load_db.py
â”‚   â””â”€â”€ run.py
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ db.py
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_etl.sh
â”‚   â”œâ”€â”€ export_json.sh
â”‚   â””â”€â”€ serve_frontend.sh
â””â”€â”€ tests/
    â”œâ”€â”€ test_parse_xml.py
    â”œâ”€â”€ test_clean_normalize.py
    â””â”€â”€ test_categorize.py
```

---

âš™ï¸ Installation

 1) Clone

```bash
git clone <your-repo-url>
cd momo-analytics
```

 2) Create & activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
```

### 3) Install dependencies

```bash
pip install -r requirements.txt
```

### 4) Environment variables

Create a `.env` file (use `.env.example` as a guide). Example values:

```
# ETL
RAW_XML_DIR=./data/raw
PROCESSED_DIR=./data/processed
DB_PATH=./data/db.sqlite3
LOG_DIR=./data/logs

# API (optional)
API_HOST=0.0.0.0
API_PORT=8000
```

---

ğŸšš ETL Pipeline

Entry point: `etl/run.py`

1. Parse XML (`etl/parse_xml.py`)

    Read SMS export(s) in XML
    Extract timestamp, amount, counterparty, reference, message
2. Clean & Normalize (`etl/clean_normalize.py`)

   * Standardize dates, currency, amounts, phone formats
   * Normalize message templates; handle duplicates
3. Categorize (`etl/categorize.py`)

   * Rules/regex to label transactions: *cash-in, cash-out, transfer, merchant, fees, reversal, airtime, bill pay*, etc.
4. Load DB (`etl/load_db.py`)

   * Create/upgrade tables; load normalized rows
   * Generate summary tables / materialized views (daily totals, by category, top counterparties)

Run:

```bash
python -m etl.run
```

Or with helper script:

```bash
bash scripts/run_etl.sh
```

Outputs:

* `data/db.sqlite3` â€“ relational store
* `data/processed/` â€“ cleaned CSV/JSON exports (optional)
* `data/logs/` â€“ run logs

---

 ğŸ—„ï¸ Database (SQLite)

Suggested tables (simplified):

transactions

* `id` (PK), `timestamp`, `direction` (in/out), `amount`, `currency`, `category`, `counterparty`, `reference`, `message_hash` (for dedupe), `raw_id`

raw\_messages

* `raw_id` (PK), `received_at`, `sender`, `body`, `source_file`

aggregates\_daily

* `date`, `total_in`, `total_out`, `net`, `txn_count`

---

ğŸ§ª Testing

Run unit tests for core stages:

```bash
pytest -q
```

 `test_parse_xml.py`: parsing correctness, sample fixtures
 `test_clean_normalize.py`: amount/date normalization, dedupe
 `test_categorize.py`: rules classification coverage

---

ğŸŒ Optional API (FastAPI)

Serve data to the dashboard or 3rdâ€‘party tools.
Run API:

```bash
uvicorn api.app:app --host ${API_HOST:-0.0.0.0} --port ${API_PORT:-8000} --reload
```

**Example endpoints** (planned):

* `GET /health` â€“ service check
* `GET /transactions?limit=...&category=...`
* `GET /analytics/daily` â€“ time series
* `GET /analytics/categories` â€“ distribution by category

`api/schemas.py` documents response models.

---

 ğŸ–¥ï¸ Frontend Dashboard

A static dashboard reads API JSON (or local JSON files exported from ETL) and visualizes time series, category breakdowns, and top entities.

**Serve locally:**

```bash
bash scripts/serve_frontend.sh
```

Open `index.html` in your browser. Core assets:

* `web/styles.css`
* `web/chart_handler.js`

**Charts & Tables**

* Daily totals (line chart)
* In vs Out vs Fees (stacked bars)
* Category distribution (doughnut/pie)
* Top counterparties (table)

---

 ğŸ§µ Usage Workflow

1. Export MoMo SMS as **XML** (e.g., from your device/backup tool), place files in `data/raw/`.
2. Configure `.env` paths if needed.
3. Run ETL to populate `db.sqlite3`.
4. Start **API** (optional).
5. Open the **dashboard** to explore insights.

---

ğŸ›¡ï¸ Data & Security Notes

* Treat MoMo data as **sensitive**. Do not commit real SMS/XML or DB files.
* `.gitignore` should exclude `data/raw/`, `data/db.sqlite3` and any secrets.
* Consider anonymization (hashing phone numbers) for demos.

---

ğŸ”§ Scripts

* `scripts/run_etl.sh` â€“ run the ETL endâ€‘toâ€‘end
* `scripts/export_json.sh` â€“ export selected tables to JSON for the frontend
* `scripts/serve_frontend.sh` â€“ quick local static server

---

 ğŸ§¾ Requirements

* Python 3.x
* lxml (or ElementTree), fastapi+uvicorn (optional), pandas (optional), pytest
* SQLite (bundled with Python)

See `requirements.txt` for exact versions.

---

 ğŸ§‘â€ğŸ’» Contributors

* **Blessing Ingabire** â€“ `blessiingab`
* **Tabitha Dorcas Akimana** â€“ `tdorcas-akim`
* **Adoleh Samuel** â€“ `AdolehSamuel`



